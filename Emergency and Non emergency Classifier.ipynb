{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLgf23moX04d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848dd9ef-4d9a-47fb-c1c8-c3e98f7560bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1935 images belonging to 2 classes.\n",
            "Found 342 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Set the path to your dataset\n",
        "train_dir = '/content/drive/MyDrive/emerg vs non emer'\n",
        "test_dir = '/content/drive/MyDrive/test'\n",
        "\n",
        "# Define the CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Preprocess and augment the training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(64, 64),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "# Preprocess the test data (only rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(64, 64),\n",
        "                                                  batch_size=20,\n",
        "                                                  class_mode='binary')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRManz69RXqV",
        "outputId": "a6c73cf1-22f2-4956-ed85-dc2eb7e6e949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPmjURhzjUSb",
        "outputId": "b4ca6a8d-b1b8-4823-a8b5-a2b3445d2fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "77/77 [==============================] - 250s 3s/step - loss: 0.6054 - accuracy: 0.7075\n",
            "Epoch 2/60\n",
            "77/77 [==============================] - 54s 686ms/step - loss: 0.6098 - accuracy: 0.7068\n",
            "Epoch 3/60\n",
            "77/77 [==============================] - 20s 264ms/step - loss: 0.5965 - accuracy: 0.7094\n",
            "Epoch 4/60\n",
            "77/77 [==============================] - 8s 103ms/step - loss: 0.5578 - accuracy: 0.7325\n",
            "Epoch 5/60\n",
            "77/77 [==============================] - 9s 113ms/step - loss: 0.5336 - accuracy: 0.7694\n",
            "Epoch 6/60\n",
            "77/77 [==============================] - 8s 98ms/step - loss: 0.5165 - accuracy: 0.7805\n",
            "Epoch 7/60\n",
            "77/77 [==============================] - 6s 83ms/step - loss: 0.4921 - accuracy: 0.7876\n",
            "Epoch 8/60\n",
            "77/77 [==============================] - 6s 83ms/step - loss: 0.4754 - accuracy: 0.7902\n",
            "Epoch 9/60\n",
            "77/77 [==============================] - 7s 95ms/step - loss: 0.4535 - accuracy: 0.8059\n",
            "Epoch 10/60\n",
            "77/77 [==============================] - 6s 84ms/step - loss: 0.4581 - accuracy: 0.8091\n",
            "Epoch 11/60\n",
            "77/77 [==============================] - 6s 83ms/step - loss: 0.4506 - accuracy: 0.8071\n",
            "Epoch 12/60\n",
            "77/77 [==============================] - 8s 98ms/step - loss: 0.4365 - accuracy: 0.8130\n",
            "Epoch 13/60\n",
            "77/77 [==============================] - 8s 98ms/step - loss: 0.4213 - accuracy: 0.8254\n",
            "Epoch 14/60\n",
            "77/77 [==============================] - 6s 83ms/step - loss: 0.4089 - accuracy: 0.8274\n",
            "Epoch 15/60\n",
            "77/77 [==============================] - 8s 99ms/step - loss: 0.3967 - accuracy: 0.8267\n",
            "Epoch 16/60\n",
            "77/77 [==============================] - 6s 83ms/step - loss: 0.3933 - accuracy: 0.8267\n",
            "Epoch 17/60\n",
            "77/77 [==============================] - 6s 84ms/step - loss: 0.3825 - accuracy: 0.8469\n",
            "Epoch 18/60\n",
            "77/77 [==============================] - 8s 99ms/step - loss: 0.3823 - accuracy: 0.8370\n",
            "Epoch 19/60\n",
            "77/77 [==============================] - 7s 93ms/step - loss: 0.3746 - accuracy: 0.8417\n",
            "Epoch 20/60\n",
            "77/77 [==============================] - 6s 84ms/step - loss: 0.3906 - accuracy: 0.8371\n",
            "Epoch 21/60\n",
            "77/77 [==============================] - 7s 88ms/step - loss: 0.3710 - accuracy: 0.8474\n",
            "Epoch 22/60\n",
            "77/77 [==============================] - 8s 98ms/step - loss: 0.3528 - accuracy: 0.8502\n",
            "Epoch 23/60\n",
            "77/77 [==============================] - 7s 91ms/step - loss: 0.3495 - accuracy: 0.8541\n",
            "Epoch 24/60\n",
            "77/77 [==============================] - 6s 84ms/step - loss: 0.3454 - accuracy: 0.8476\n",
            "Epoch 25/60\n",
            "77/77 [==============================] - 7s 89ms/step - loss: 0.3563 - accuracy: 0.8417\n",
            "Epoch 26/60\n",
            "77/77 [==============================] - 7s 95ms/step - loss: 0.3546 - accuracy: 0.8547\n",
            "Epoch 27/60\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.3395 - accuracy: 0.8638\n",
            "Epoch 28/60\n",
            "77/77 [==============================] - 6s 83ms/step - loss: 0.3271 - accuracy: 0.8632\n",
            "Epoch 29/60\n",
            "77/77 [==============================] - 7s 87ms/step - loss: 0.3483 - accuracy: 0.8534\n",
            "Epoch 30/60\n",
            "77/77 [==============================] - 7s 96ms/step - loss: 0.3158 - accuracy: 0.8782\n",
            "Epoch 31/60\n",
            "77/77 [==============================] - 7s 89ms/step - loss: 0.3324 - accuracy: 0.8632\n",
            "Epoch 32/60\n",
            "77/77 [==============================] - 8s 103ms/step - loss: 0.3320 - accuracy: 0.8632\n",
            "Epoch 33/60\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.3115 - accuracy: 0.8743\n",
            "Epoch 34/60\n",
            "77/77 [==============================] - 8s 99ms/step - loss: 0.3031 - accuracy: 0.8775\n",
            "Epoch 35/60\n",
            "77/77 [==============================] - 6s 84ms/step - loss: 0.2978 - accuracy: 0.8756\n",
            "Epoch 36/60\n",
            "77/77 [==============================] - 6s 83ms/step - loss: 0.3067 - accuracy: 0.8740\n",
            "Epoch 37/60\n",
            "77/77 [==============================] - 8s 99ms/step - loss: 0.2929 - accuracy: 0.8857\n",
            "Epoch 38/60\n",
            "77/77 [==============================] - 6s 83ms/step - loss: 0.2820 - accuracy: 0.8801\n",
            "Epoch 39/60\n",
            "77/77 [==============================] - 8s 103ms/step - loss: 0.2770 - accuracy: 0.8925\n",
            "Epoch 40/60\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.3386 - accuracy: 0.8586\n",
            "Epoch 41/60\n",
            "77/77 [==============================] - 7s 88ms/step - loss: 0.2882 - accuracy: 0.8879\n",
            "Epoch 42/60\n",
            "77/77 [==============================] - 7s 93ms/step - loss: 0.3135 - accuracy: 0.8710\n",
            "Epoch 43/60\n",
            "77/77 [==============================] - 7s 88ms/step - loss: 0.2935 - accuracy: 0.8821\n",
            "Epoch 44/60\n",
            "77/77 [==============================] - 7s 94ms/step - loss: 0.2700 - accuracy: 0.8938\n",
            "Epoch 45/60\n",
            "77/77 [==============================] - 6s 84ms/step - loss: 0.2897 - accuracy: 0.8808\n",
            "Epoch 46/60\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.2856 - accuracy: 0.8847\n",
            "Epoch 47/60\n",
            "77/77 [==============================] - 8s 102ms/step - loss: 0.2795 - accuracy: 0.8795\n",
            "Epoch 48/60\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.2858 - accuracy: 0.8890\n",
            "Epoch 49/60\n",
            "77/77 [==============================] - 8s 99ms/step - loss: 0.2640 - accuracy: 0.8990\n",
            "Epoch 50/60\n",
            "77/77 [==============================] - 6s 84ms/step - loss: 0.2654 - accuracy: 0.8997\n",
            "Epoch 51/60\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.2553 - accuracy: 0.8879\n",
            "Epoch 52/60\n",
            "77/77 [==============================] - 7s 88ms/step - loss: 0.2541 - accuracy: 0.9003\n",
            "Epoch 53/60\n",
            "77/77 [==============================] - 8s 104ms/step - loss: 0.2537 - accuracy: 0.9003\n",
            "Epoch 54/60\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.2351 - accuracy: 0.9055\n",
            "Epoch 55/60\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.2734 - accuracy: 0.8853\n",
            "Epoch 56/60\n",
            "77/77 [==============================] - 7s 93ms/step - loss: 0.2636 - accuracy: 0.8873\n",
            "Epoch 57/60\n",
            "77/77 [==============================] - 8s 99ms/step - loss: 0.2637 - accuracy: 0.8951\n",
            "Epoch 58/60\n",
            "77/77 [==============================] - 6s 83ms/step - loss: 0.2410 - accuracy: 0.9010\n",
            "Epoch 59/60\n",
            "77/77 [==============================] - 7s 87ms/step - loss: 0.2349 - accuracy: 0.9123\n",
            "Epoch 60/60\n",
            "77/77 [==============================] - 7s 88ms/step - loss: 0.2628 - accuracy: 0.8938\n"
          ]
        }
      ],
      "source": [
        "model.fit(train_generator,steps_per_epoch=77,epochs=60)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('emergency_classifier.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZjnZiFvEqa-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p3lig9FvjWCP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-wDAohwhFi5",
        "outputId": "5d69889b-6532-4294-a731-476c5d17534e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 122s 7s/step - loss: 0.2474 - accuracy: 0.9123\n",
            "18/18 [==============================] - 1s 52ms/step\n",
            "Test Loss: 0.24744488298892975\n",
            "Test Accuracy: 0.9122806787490845\n",
            "Precision: 0.5964912280701754\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the saved model\n",
        "model = tf.keras.models.load_model('emergency_classifier.h5')\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "# Predict the classes for the test data\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = np.round(predictions).flatten()\n",
        "\n",
        "# Calculate the precision metric\n",
        "true_classes = test_generator.classes\n",
        "precision = np.sum(predicted_classes == true_classes) / len(true_classes)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "print('Precision:', precision)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REPoJJzZjYc_",
        "outputId": "6a01bd6b-405c-4507-cc2a-6afe85f358e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.746606334841629\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(true_classes, predicted_classes)\n",
        "print('Recall:', recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9zSI5mrbZMu",
        "outputId": "40add41a-6195-4af5-bfe9-51d7eb17c447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "Emergency Vehicle\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "import keras.utils as image\n",
        "test_image=image.load_img('/content/drive/MyDrive/emerg vs non emer/emergency/426.jpg',target_size=(64,64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=model.predict(test_image)\n",
        "train_generator.class_indices\n",
        "if result[0][0]==1:\n",
        "  prediction='Non emergency vehicle'\n",
        "else:\n",
        "  prediction='Emergency Vehicle'\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ogo2Rpy9NH7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TtqICDf7S1x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbGXPww6xEMi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4lS97zsFXbz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaBzPF-Hz2Rr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOK1OR_dpp2e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdEeIlE3Hfxs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e06wh6qPHKJQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFAdD0V3X8YH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Acxhtfs9rfSe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsH9reI6x8yF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXqYh8_8zj-0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiJnyLOo1uTb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmdqzICqWC1b"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzhq5o4ICHuy"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83LIV9u5ACii"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Set the path to your dataset\n",
        "train_dir = '/content/drive/MyDrive/emerg vs non emer'\n",
        "test_dir = '/content/drive/MyDrive/test'\n",
        "\n",
        "# Load the ResNet50 model\n",
        "resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the ResNet50 model\n",
        "for layer in resnet50.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model based on ResNet50\n",
        "model = tf.keras.models.Sequential([\n",
        "    resnet50,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Preprocess and augment the training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "# Preprocess the test data (only rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=20,\n",
        "                                                  class_mode='binary')\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, steps_per_epoch=77, epochs=60)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('emergency_classifier_resnet50.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5R_vYg4L4nm"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model,open('/content/emergency_classifier_resnet50.h5','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGnSNf-F1opu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Set the path to your dataset\n",
        "train_dir = '/content/drive/MyDrive/emerg vs non emer'\n",
        "test_dir = '/content/drive/MyDrive/test'\n",
        "\n",
        "# Load the MobileNetV2 model\n",
        "mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the MobileNetV2 model\n",
        "for layer in mobilenetv2.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model based on MobileNetV2\n",
        "model = tf.keras.models.Sequential([\n",
        "    mobilenetv2,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Preprocess and augment the training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "# Preprocess the test data (only rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=20,\n",
        "                                                  class_mode='binary')\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, steps_per_epoch=77, epochs=60)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('emergency_classifier_mobilenetv2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsbLM98j1sdF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model,open('emergency_classifier_mobilenetv2.h5','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6yUyQ8QZW-7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import NASNetMobile\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Set the path to your dataset\n",
        "train_dir = '/content/drive/MyDrive/emerg vs non emer'\n",
        "test_dir = '/content/drive/MyDrive/test'\n",
        "\n",
        "# Load the NASNetMobile model\n",
        "nasnet = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the NASNetMobile model\n",
        "for layer in nasnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model based on NASNetMobile\n",
        "model = tf.keras.models.Sequential([\n",
        "    nasnet,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Preprocess and augment the training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "# Preprocess the test data (only rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=20,\n",
        "                                                  class_mode='binary')\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, steps_per_epoch=77, epochs=60)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('emergency_classifier_nasnetmobile.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHlElY3DIMoH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import SqueezeNet\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Set the path to your dataset\n",
        "train_dir = '/content/drive/MyDrive/emerg vs non emer'\n",
        "test_dir = '/content/drive/MyDrive/test'\n",
        "# Load the SqueezeNet model\n",
        "squeezenet = SqueezeNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the SqueezeNet model\n",
        "for layer in squeezenet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model based on SqueezeNet\n",
        "model = tf.keras.models.Sequential([\n",
        "    squeezenet,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Preprocess and augment the training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "# Preprocess the test data (only rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=20,\n",
        "                                                  class_mode='binary')\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, steps_per_epoch=77, epochs=60)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('emergency_classifier_squeezenet.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AhJ337XbV-R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}